version: "3"

tasks:
  default:
    desc: "Generate workspaceInfo and rebuild/test"
    cmds:
      - task: generate-rwl-config
      - task: build-rwl  
      - task: run-rwl-discovery

  clean:
    desc: "Run cleanup tasks"
    cmds:
      - task: check-and-cleanup-terraform
      - task: clean-rwl-discovery

  build-infra:
    desc: "Build test infrastructure"
    cmds:
      - task: build-terraform-infra


  generate-rwl-config:
    desc: "Generate RunWhen Local configuration (workspaceInfo.yaml)"
    env:
      ARM_SUBSCRIPTION_ID: "{{.TF_VAR_subscription_id}}"
      AZ_TENANT_ID: "{{.AZ_TENANT_ID}}"
      AZ_CLIENT_SECRET: "{{.AZ_CLIENT_SECRET}}"
      AZ_CLIENT_ID: "{{.AZ_CLIENT_ID}}"
      RW_WORKSPACE: '{{.RW_WORKSPACE | default "my-workspace"}}'
    cmds:
      - |
        repo_url=$(git config --get remote.origin.url)
        branch_name=$(git rev-parse --abbrev-ref HEAD)
        codebundle=$(basename "$(dirname "$PWD")")

        # Fetch individual cluster details from Terraform state
        pushd terraform > /dev/null
        cluster_name=$(terraform show -json terraform.tfstate | jq -r '
          .values.outputs.cluster_name.value')
        cluster_server=$(terraform show -json terraform.tfstate | jq -r '
          .values.outputs.cluster_fqdn.value')
        cluster_resource_group=$(terraform show -json terraform.tfstate | jq -r '
          .values.outputs.cluster_rg.value')
        cluster_sub=$(terraform show -json terraform.tfstate | jq -r '
          .values.outputs.cluster_sub.value')

        popd > /dev/null

        # Check if any of the required cluster variables are empty
        if [ -z "$cluster_name" ] || [ -z "$cluster_server" ] || [ -z "$cluster_resource_group" ]; then
          echo "Error: Missing cluster details. Ensure Terraform plan has been applied."
          exit 1
        fi

        # Generate workspaceInfo.yaml with fetched cluster details
        cat <<EOF > workspaceInfo.yaml
        workspaceName: "$RW_WORKSPACE"
        workspaceOwnerEmail: authors@runwhen.com
        defaultLocation: location-01
        defaultLOD: none
        cloudConfig:
          kubernetes:             
            kubeconfigFile: /shared/kubeconfig.secret
            contexts: 
              sandbox-cluster-1: 
                defaultNamespaceLOD: basic
          azure:
            subscriptionId: "$ARM_SUBSCRIPTION_ID"
            tenantId: "$AZ_TENANT_ID"
            clientId: "$AZ_CLIENT_ID"
            clientSecret: "$AZ_CLIENT_SECRET"
            aksClusters: 
              clusters: 
                - name: $cluster_name
                  server: https://$cluster_server:443
                  resource_group: $cluster_resource_group
                  subscriptionId: $cluster_sub
                  defaultNamespaceLOD: detailed
            resourceGroupLevelOfDetails:
              $cluster_resource_group: detailed
        codeCollections: []
        custom: 
          kubernetes_distribution_binary: kubectl
        EOF
    silent: true

  build-rwl:
    desc: "Build RWL test image"
    cmds:
      - |
        BUILD_DIR=../../../src/
        CONTAINER_NAME="RunWhenLocal"
        if docker ps -q --filter "name=$CONTAINER_NAME" | grep -q .; then
          echo "Stopping and removing existing container $CONTAINER_NAME..."
          docker stop $CONTAINER_NAME && docker rm $CONTAINER_NAME
        elif docker ps -a -q --filter "name=$CONTAINER_NAME" | grep -q .; then
          echo "Removing existing stopped container $CONTAINER_NAME..."
          docker rm $CONTAINER_NAME
        else
          echo "No existing container named $CONTAINER_NAME found."
        fi
        
        echo "Cleaning up output directory..."
        rm -rf output || { echo "Failed to remove output directory"; exit 1; }
        mkdir output && chmod 777 output || { echo "Failed to set permissions"; exit 1; }

        ## Building Container Image
        docker buildx build --builder mybuilder --platform linux/amd64  -t runwhen-local:test -f $BUILD_DIR/Dockerfile $BUILD_DIR --load
    silent: true

  run-rwl-discovery:
    desc: "Run RunWhen Local Discovery on test infrastructure"
    cmds:
      - |
        rm slx_count.txt || true
        CONTAINER_NAME="RunWhenLocal"    
        if docker ps -q --filter "name=$CONTAINER_NAME" | grep -q .; then
          echo "Stopping and removing existing container $CONTAINER_NAME..."
          docker stop $CONTAINER_NAME && docker rm $CONTAINER_NAME
        elif docker ps -a -q --filter "name=$CONTAINER_NAME" | grep -q .; then
          echo "Removing existing stopped container $CONTAINER_NAME..."
          docker rm $CONTAINER_NAME
        else
          echo "No existing container named $CONTAINER_NAME found."
        fi
        
        echo "Cleaning up output directory..."
        rm -rf output || { echo "Failed to remove output directory"; exit 1; }
        mkdir output && chmod 777 output || { echo "Failed to set permissions"; exit 1; }

        echo "Starting new container $CONTAINER_NAME..."

        docker run -e DEBUG_LOGS=true --name $CONTAINER_NAME -p 8081:8081 -v $(pwd):/shared -d runwhen-local:test || {
          echo "Failed to start container"; exit 1;
        }

        echo "Running workspace builder script in container..."
        docker exec -w /workspace-builder $CONTAINER_NAME ./run.sh $1 --verbose || {
          echo "Error executing script in container"; exit 1;
        }

        echo "Review generated config files under output/workspaces/"
        total_slxs=$(find $(find 'output/' -type d -name 'slxs') -mindepth 1 -type d | wc -l)
        echo "Total SLXs: $total_slxs"
        echo "$total_slxs" > slx_count.txt
    silent: true
  
  ci-run-rwl-discovery:
    desc: "Run RunWhen Local Discovery on test infrastructure"
    cmds:
      - |
        rm slx_count.txt || true
        CONTAINER_NAME="RunWhenLocal"    
        if docker ps -q --filter "name=$CONTAINER_NAME" | grep -q .; then
          echo "Stopping and removing existing container $CONTAINER_NAME..."
          docker stop $CONTAINER_NAME && docker rm $CONTAINER_NAME
        elif docker ps -a -q --filter "name=$CONTAINER_NAME" | grep -q .; then
          echo "Removing existing stopped container $CONTAINER_NAME..."
          docker rm $CONTAINER_NAME
        else
          echo "No existing container named $CONTAINER_NAME found."
        fi
        
        echo "Cleaning up output directory..."
        rm -rf output || { echo "Failed to remove output directory"; exit 1; }
        mkdir output && chmod 777 output || { echo "Failed to set permissions"; exit 1; }
        chmod 777 . 

        echo "Starting new container $CONTAINER_NAME..."

        # 1. Start container in the background
        docker run -d \
          -e WB_DEBUG_SUPPRESS_CHEAT_SHEET="true" \
          -e DEBUG_LOGS=true \
          --name "$CONTAINER_NAME" \
          -p 8081:8081 \
          -v "$(pwd):/shared" \
          runwhen-local:test

        # 2. Follow the main container logs in the background (if you care about them)
        docker logs -f "$CONTAINER_NAME" &

        # 3. Now exec the script. Its stdout goes to your pipeline.
        #    By default, docker exec prints to the current terminal/session.
        docker exec -w /workspace-builder "$CONTAINER_NAME" ./run.sh "$1" --verbose 2>&1 | tee run_sh_output.log

        # 4. (Optional) Stop container if you no longer need it running
        docker stop "$CONTAINER_NAME"
        docker rm "$CONTAINER_NAME"  

        echo "Review generated config files under output/workspaces/"
        total_slxs=$(find $(find 'output/' -type d -name 'slxs') -mindepth 1 -type d | wc -l)
        echo "Total SLXs: $total_slxs"
        echo "$total_slxs" > slx_count.txt
    silent: true

  ci-test-1:
    desc: "Run CI Discovery Test 1 - K8s & AKS - defaultLOD None, K8s context defaultNamespaceLOD Basic, AKS defaultNamespaceLOD Detailed"
    env:
      ARM_SUBSCRIPTION_ID: "{{.TF_VAR_subscription_id}}"
      AZ_TENANT_ID: "{{.AZ_TENANT_ID}}"
      AZ_CLIENT_SECRET: "{{.AZ_CLIENT_SECRET}}"
      AZ_CLIENT_ID: "{{.AZ_CLIENT_ID}}"
      RW_WORKSPACE: '{{.RW_WORKSPACE | default "my-workspace"}}'
    vars: 
      EXPECTED_SLXS: "30"
    cmds:
      - |
        repo_url=$(git config --get remote.origin.url)
        branch_name=$(git rev-parse --abbrev-ref HEAD)
        codebundle=$(basename "$(dirname "$PWD")")

        # Fetch individual cluster details from Terraform state
        pushd terraform > /dev/null
        cluster_name=$(terraform show -json | jq -r '
          .values.outputs.cluster_name.value')
        cluster_server=$(terraform show -json | jq -r '
          .values.outputs.cluster_fqdn.value')
        cluster_resource_group=$(terraform show -json | jq -r '
          .values.outputs.cluster_rg.value')
        cluster_sub=$(terraform show -json | jq -r '
          .values.outputs.cluster_sub.value')

        popd > /dev/null

        # Check if any of the required cluster variables are empty
        if [ -z "$cluster_name" ] || [ -z "$cluster_server" ] || [ -z "$cluster_resource_group" ]; then
          echo "Error: Missing cluster details. Ensure Terraform plan has been applied."
          exit 1
        fi

        # Generate workspaceInfo.yaml with fetched cluster details
        cat <<EOF > workspaceInfo.yaml
        workspaceName: "$RW_WORKSPACE"
        workspaceOwnerEmail: authors@runwhen.com
        defaultLocation: location-01
        defaultLOD: none
        cloudConfig:
          kubernetes:             
            kubeconfigFile: /shared/kubeconfig.secret
            contexts: 
              sandbox-cluster-1: 
                defaultNamespaceLOD: basic
            namespaces:
              - ci-verify-basic
          azure:
            subscriptionId: "$ARM_SUBSCRIPTION_ID"
            tenantId: "$AZ_TENANT_ID"
            clientId: "$AZ_CLIENT_ID"
            clientSecret: "$AZ_CLIENT_SECRET"
            aksClusters: 
              clusters: 
                - name: $cluster_name
                  server: https://$cluster_server:443
                  resource_group: $cluster_resource_group
                  subscriptionId: $cluster_sub
                  defaultNamespaceLOD: detailed
              namespaces: 
                - kube-system
            resourceGroupLevelOfDetails:
              $cluster_resource_group: detailed
        codeCollections: []
        custom: 
          kubernetes_distribution_binary: kubectl
        EOF

      - task: ci-run-rwl-discovery
      - task: verify-slx-count
        vars:
          EXPECTED_SLX_COUNT: "{{.EXPECTED_SLXS}}"
    silent: true

  ci-test-2:
      desc: "Run CI Discovery Test 2 - K8s & AKS - defaultLOD None, No K8s Context defaultNamespaceLOD, AKS defaultNamespaceLOD detailed"
      env:
        ARM_SUBSCRIPTION_ID: "{{.TF_VAR_subscription_id}}"
        AZ_TENANT_ID: "{{.AZ_TENANT_ID}}"
        AZ_CLIENT_SECRET: "{{.AZ_CLIENT_SECRET}}"
        AZ_CLIENT_ID: "{{.AZ_CLIENT_ID}}"
        RW_WORKSPACE: '{{.RW_WORKSPACE | default "my-workspace"}}'
      vars: 
        EXPECTED_SLXS: "39"
      cmds:
        - |
          repo_url=$(git config --get remote.origin.url)
          branch_name=$(git rev-parse --abbrev-ref HEAD)
          codebundle=$(basename "$(dirname "$PWD")")

          # Fetch individual cluster details from Terraform state
          pushd terraform > /dev/null
          cluster_name=$(terraform show -json | jq -r '
            .values.outputs.cluster_name.value')
          cluster_server=$(terraform show -json | jq -r '
            .values.outputs.cluster_fqdn.value')
          cluster_resource_group=$(terraform show -json | jq -r '
            .values.outputs.cluster_rg.value')
          cluster_sub=$(terraform show -json | jq -r '
            .values.outputs.cluster_sub.value')

          popd > /dev/null

          # Check if any of the required cluster variables are empty
          if [ -z "$cluster_name" ] || [ -z "$cluster_server" ] || [ -z "$cluster_resource_group" ]; then
            echo "Error: Missing cluster details. Ensure Terraform plan has been applied."
            exit 1
          fi

          # Generate workspaceInfo.yaml with fetched cluster details
          cat <<EOF > workspaceInfo.yaml
          workspaceName: "$RW_WORKSPACE"
          workspaceOwnerEmail: authors@runwhen.com
          defaultLocation: location-01
          defaultLOD: none
          cloudConfig:
            kubernetes:             
              kubeconfigFile: /shared/kubeconfig.secret
            azure:
              subscriptionId: "$ARM_SUBSCRIPTION_ID"
              tenantId: "$AZ_TENANT_ID"
              clientId: "$AZ_CLIENT_ID"
              clientSecret: "$AZ_CLIENT_SECRET"
              aksClusters: 
                clusters: 
                  - name: $cluster_name
                    server: https://$cluster_server:443
                    resource_group: $cluster_resource_group
                    subscriptionId: $cluster_sub
                    defaultNamespaceLOD: detailed
              resourceGroupLevelOfDetails:
                $cluster_resource_group: detailed
          codeCollections: []
          custom: 
            kubernetes_distribution_binary: kubectl
          EOF

        - task: ci-run-rwl-discovery
        - task: verify-slx-count
          vars:
            EXPECTED_SLX_COUNT: "{{.EXPECTED_SLXS}}"
      silent: true

  ci-test-3:
      desc: "Run CI Discovery Test 3 - K8s & AKS - defaultLOD None, K8s cluster defaultNamespaceLOD none, AKS defaultNamespaceLOD none, single azure.resourceGroupLevelOfDetails detailed"
      env:
        ARM_SUBSCRIPTION_ID: "{{.TF_VAR_subscription_id}}"
        AZ_TENANT_ID: "{{.AZ_TENANT_ID}}"
        AZ_CLIENT_SECRET: "{{.AZ_CLIENT_SECRET}}"
        AZ_CLIENT_ID: "{{.AZ_CLIENT_ID}}"
        RW_WORKSPACE: '{{.RW_WORKSPACE | default "my-workspace"}}'
      vars: 
        EXPECTED_SLXS: "7"
      cmds:
        - |
          repo_url=$(git config --get remote.origin.url)
          branch_name=$(git rev-parse --abbrev-ref HEAD)
          codebundle=$(basename "$(dirname "$PWD")")

          # Fetch individual cluster details from Terraform state
          pushd terraform > /dev/null
          cluster_name=$(terraform show -json  | jq -r '
            .values.outputs.cluster_name.value')
          cluster_server=$(terraform show -json  | jq -r '
            .values.outputs.cluster_fqdn.value')
          cluster_resource_group=$(terraform show -json  | jq -r '
            .values.outputs.cluster_rg.value')
          cluster_sub=$(terraform show -json  | jq -r '
            .values.outputs.cluster_sub.value')
          node_pool_rg=$(terraform show -json  | jq -r '
            .values.root_module.resources[] | select(.type == "azurerm_kubernetes_cluster") | .values.node_resource_group')
          popd > /dev/null

          # Check if any of the required cluster variables are empty
          if [ -z "$cluster_name" ] || [ -z "$cluster_server" ] || [ -z "$cluster_resource_group" ]; then
            echo "Error: Missing cluster details. Ensure Terraform plan has been applied."
            exit 1
          fi

          # Generate workspaceInfo.yaml with fetched cluster details
          cat <<EOF > workspaceInfo.yaml
          workspaceName: "$RW_WORKSPACE"
          workspaceOwnerEmail: authors@runwhen.com
          defaultLocation: location-01
          defaultLOD: none
          cloudConfig:
            kubernetes:             
              kubeconfigFile: /shared/kubeconfig.secret
              contexts:
                sandbox-cluster-1: 
                  defaultNamespaceLOD: none
            azure:
              subscriptionId: "$ARM_SUBSCRIPTION_ID"
              tenantId: "$AZ_TENANT_ID"
              clientId: "$AZ_CLIENT_ID"
              clientSecret: "$AZ_CLIENT_SECRET"
              aksClusters: 
                clusters: 
                  - name: $cluster_name
                    server: https://$cluster_server:443
                    resource_group: $cluster_resource_group
                    subscriptionId: $cluster_sub
                    defaultNamespaceLOD: none
              resourceGroupLevelOfDetails:
                $cluster_resource_group: detailed
                $node_pool_rg: detailed

          codeCollections: []
            # - repoURL: "https://github.com/runwhen-contrib/rw-cli-codecollection"
            #   branch: "main"
            #   codeBundles: ["k8s-namespace-healthcheck", "azure-aks-triage", "k8s-deployment-healthcheck"]
          custom: 
            kubernetes_distribution_binary: kubectl
          EOF

        - task: ci-run-rwl-discovery
        - task: verify-slx-count
          vars:
            EXPECTED_SLX_COUNT: "{{.EXPECTED_SLXS}}"
      silent: true

  ci-test-4:
      desc: "Run CI Discovery Test 4 - AKS only - defaultLOD none, no K8s Cluster, AKS defaultNamespaceLOD none, kube-system lod detailed from annotation"
      env:
        ARM_SUBSCRIPTION_ID: "{{.TF_VAR_subscription_id}}"
        AZ_TENANT_ID: "{{.AZ_TENANT_ID}}"
        AZ_CLIENT_SECRET: "{{.AZ_CLIENT_SECRET}}"
        AZ_CLIENT_ID: "{{.AZ_CLIENT_ID}}"
        RW_WORKSPACE: '{{.RW_WORKSPACE | default "my-workspace"}}'
      vars: 
        EXPECTED_SLXS: "5"
      cmds:
        - |
          repo_url=$(git config --get remote.origin.url)
          branch_name=$(git rev-parse --abbrev-ref HEAD)
          codebundle=$(basename "$(dirname "$PWD")")

          # Fetch individual cluster details from Terraform state
          pushd terraform > /dev/null
          cluster_name=$(terraform show -json | jq -r '
            .values.outputs.cluster_name.value')
          cluster_server=$(terraform show -json  | jq -r '
            .values.outputs.cluster_fqdn.value')
          cluster_resource_group=$(terraform show -json | jq -r '
            .values.outputs.cluster_rg.value')
          cluster_sub=$(terraform show -json | jq -r '
            .values.outputs.cluster_sub.value')
          node_pool_rg=$(terraform show -json  | jq -r '
            .values.root_module.resources[] | select(.type == "azurerm_kubernetes_cluster") | .values.node_resource_group')

          popd > /dev/null

          # Check if any of the required cluster variables are empty
          if [ -z "$cluster_name" ] || [ -z "$cluster_server" ] || [ -z "$cluster_resource_group" ]; then
            echo "Error: Missing cluster details. Ensure Terraform plan has been applied."
            exit 1
          fi

          # Generate workspaceInfo.yaml with fetched cluster details
          cat <<EOF > workspaceInfo.yaml
          workspaceName: "$RW_WORKSPACE"
          workspaceOwnerEmail: authors@runwhen.com
          defaultLocation: location-01
          defaultLOD: none
          cloudConfig:
            kubernetes: null
            azure:
              subscriptionId: "$ARM_SUBSCRIPTION_ID"
              tenantId: "$AZ_TENANT_ID"
              clientId: "$AZ_CLIENT_ID"
              clientSecret: "$AZ_CLIENT_SECRET"
              aksClusters: 
                clusters: 
                  - name: $cluster_name
                    server: https://$cluster_server:443
                    resource_group: $cluster_resource_group
                    subscriptionId: $cluster_sub
                    defaultNamespaceLOD: none
              resourceGroupLevelOfDetails:
                $cluster_resource_group: detailed
                $node_pool_rg: detailed
          codeCollections: []
          custom: 
            kubernetes_distribution_binary: kubectl
          EOF

        - task: ci-run-rwl-discovery
        - task: verify-slx-count
          vars:
            EXPECTED_SLX_COUNT: "{{.EXPECTED_SLXS}}"
      silent: true

  ci-test-5:
      desc: "Run CI Discovery Test 5 - K8s only - defaultLOD basic, K8s defaultNamespaceLOD basic (1 ns), no AKS cluster"
      env:
        ARM_SUBSCRIPTION_ID: "{{.TF_VAR_subscription_id}}"
        AZ_TENANT_ID: "{{.AZ_TENANT_ID}}"
        AZ_CLIENT_SECRET: "{{.AZ_CLIENT_SECRET}}"
        AZ_CLIENT_ID: "{{.AZ_CLIENT_ID}}"
        RW_WORKSPACE: '{{.RW_WORKSPACE | default "my-workspace"}}'
      vars: 
        EXPECTED_SLXS: "6"
      cmds:
        - |
          repo_url=$(git config --get remote.origin.url)
          branch_name=$(git rev-parse --abbrev-ref HEAD)
          codebundle=$(basename "$(dirname "$PWD")")

          # Fetch individual cluster details from Terraform state
          pushd terraform > /dev/null
          cluster_name=$(terraform show -json  | jq -r '
            .values.outputs.cluster_name.value')
          cluster_server=$(terraform show -json  | jq -r '
            .values.outputs.cluster_fqdn.value')
          cluster_resource_group=$(terraform show -json  | jq -r '
            .values.outputs.cluster_rg.value')
          cluster_sub=$(terraform show -json | jq -r '
            .values.outputs.cluster_sub.value')

          popd > /dev/null

          # Check if any of the required cluster variables are empty
          if [ -z "$cluster_name" ] || [ -z "$cluster_server" ] || [ -z "$cluster_resource_group" ]; then
            echo "Error: Missing cluster details. Ensure Terraform plan has been applied."
            exit 1
          fi

          # Generate workspaceInfo.yaml with fetched cluster details
          cat <<EOF > workspaceInfo.yaml
          workspaceName: "$RW_WORKSPACE"
          workspaceOwnerEmail: authors@runwhen.com
          defaultLocation: location-01
          defaultLOD: none
          cloudConfig:
            kubernetes:             
              kubeconfigFile: /shared/kubeconfig.secret
              contexts:
                sandbox-cluster-1: 
                  defaultNamespaceLOD: basic
              namespaces:
                - ci-verify-basic
            azure:
              subscriptionId: "$ARM_SUBSCRIPTION_ID"
              tenantId: "$AZ_TENANT_ID"
              clientId: "$AZ_CLIENT_ID"
              clientSecret: "$AZ_CLIENT_SECRET"
              resourceGroupLevelOfDetails:
                $cluster_resource_group: detailed
          codeCollections: []
          custom: 
            kubernetes_distribution_binary: kubectl
          EOF

        - task: ci-run-rwl-discovery
        - task: verify-slx-count
          vars:
            EXPECTED_SLX_COUNT: "{{.EXPECTED_SLXS}}"
      silent: true

  install-deployment: 
    desc: "Install basic runwhen-local deployment"
    cmds: 
      - | 

        # Fetch individual cluster details from Terraform state
        pushd terraform > /dev/null
        cluster_name=$(terraform show -json terraform.tfstate | jq -r '
          .values.outputs.cluster_name.value')
        cluster_server=$(terraform show -json terraform.tfstate | jq -r '
          .values.outputs.cluster_fqdn.value')
        cluster_resource_group=$(terraform show -json terraform.tfstate | jq -r '
          .values.outputs.cluster_rg.value')
        cluster_sub=$(terraform show -json terraform.tfstate | jq -r '
          .values.outputs.cluster_sub.value')

        popd > /dev/null
        az aks get-credentials --resource-group $cluster_resource_group --name $cluster_name --overwrite-existing
        kubelogin convert-kubeconfig -l azurecli
        namespace=runwhen-local
        kubectl create ns $namespace
        helm repo add runwhen-contrib https://runwhen-contrib.github.io/helm-charts
        helm repo update
        helm install runwhen-local runwhen-contrib/runwhen-local -n $namespace

  check-terraform-infra:
    desc: "Check if Terraform has any deployed infrastructure in the terraform subdirectory"
    cmds:
      - |
        # Navigate to the Terraform directory
        if [ ! -d "terraform" ]; then
          echo "Terraform directory not found."
          exit 1
        fi
        cd terraform

        # Check if Terraform state file exists
        if [ ! -f "terraform.tfstate" ]; then
          echo "No Terraform state file found in the terraform directory. No infrastructure is deployed."
          exit 0
        fi

        # List resources in Terraform state
        resources=$(terraform state list)

        # Check if any resources are listed in the state file
        if [ -n "$resources" ]; then
          echo "Deployed infrastructure detected."
          echo "$resources"
          exit 0
        else
          echo "No deployed infrastructure found in Terraform state."
          exit 0
        fi
    silent: true

  build-terraform-infra:
    desc: "Run terraform apply"
    cmds:
      - |

        # Navigate to the Terraform directory
        if [ -d "terraform" ]; then
          cd terraform
        else
          echo "Terraform directory not found. Terraform apply aborted."
          exit 1
        fi
        task env-setup
        task format-and-init-terraform
        echo "Starting Terraform Build of Terraform infrastructure..."
        terraform apply -auto-approve -lock=false || {
          echo "Failed to clean up Terraform infrastructure."
          exit 1
        }
        echo "Terraform infrastructure build completed."

    silent: true

  cleanup-terraform-infra:
    desc: "Cleanup deployed Terraform infrastructure"
    cmds:
      - |

        # Navigate to the Terraform directory
        if [ -d "terraform" ]; then
          cd terraform
        else
          echo "Terraform directory not found. Cleanup aborted."
          exit 1
        fi

        echo "Starting cleanup of Terraform infrastructure..."
        terraform destroy -auto-approve -lock=false || {
          echo "Failed to clean up Terraform infrastructure."
          exit 1
        }
        echo "Terraform infrastructure cleanup completed."
    silent: true

  check-and-cleanup-terraform:
    desc: "Check and clean up deployed Terraform infrastructure if it exists"
    cmds:
      - |
        # Capture the output of check-terraform-infra
        infra_output=$(task check-terraform-infra | tee /dev/tty)

        # Check if output contains indication of deployed infrastructure
        if echo "$infra_output" | grep -q "Deployed infrastructure detected"; then
          echo "Infrastructure detected; proceeding with cleanup."
          task cleanup-terraform-infra
        else
          echo "No deployed infrastructure found; no cleanup required."
        fi
    silent: true

  clean-rwl-discovery:
    desc: "Check and clean up RunWhen Local discovery output"
    cmds:
      - |
        rm -rf output
        rm workspaceInfo.yaml
    silent: true


  verify-slx-count: 
    desc: "Validate SLX Count in CI test"
    vars:
      EXPECTED_SLX_COUNT: "{{.EXPECTED_SLX_COUNT | default `0`}}"
    cmds: 
      - |
          total_slxs=$(cat slx_count.txt)
          echo "---Validating SLX Count---"
          echo "Total SLXs: $total_slxs (Expected: {{.EXPECTED_SLX_COUNT}})"
          if [[ "$total_slxs" -lt "{{.EXPECTED_SLX_COUNT}}" ]]; then
            echo -e "\033[31m❌ Total SLX count failed\033[0m"
            exit 1
          else
            echo -e "\033[32m✔️ SLX Validation Passed\033[0m"
            exit 0
          fi
    silent: true