version: "3"

tasks:
  default:
    desc: "Generate workspaceInfo and rebuild/test"
    cmds:
      - task: generate-rwl-config-basic
      - task: build-rwl
      - task: run-rwl-discovery

  clean:
    desc: "Run cleanup tasks"
    cmds:
      - task: clean-rwl-discovery

  generate-rwl-config-detailed:
    desc: "Generate RunWhen Local configuration (workspaceInfo.yaml)"
    env:
      RW_WORKSPACE: '{{.RW_WORKSPACE | default "my-workspace"}}'
    cmds:
      - |
        # Generate workspaceInfo.yaml with fetched cluster details
        cat <<EOF > workspaceInfo.yaml
        workspaceName: "$RW_WORKSPACE"
        workspaceOwnerEmail: authors@runwhen.com
        defaultLocation: location-01
        defaultLOD: detailed
        cloudConfig:
          kubernetes:             
            kubeconfigFile: /shared/kubeconfig.secret
            contexts:
              sandbox-cluster-1: 
                defaultNamespaceLOD: detailed
        codeCollections: []
        # codeCollections: 
        #   - repoURL: "https://github.com/runwhen-contrib/rw-cli-codecollection"
        #     branch: "main"
        #     codeBundles: ["k8s-namespace-healthcheck", "k8s-deployment-healthcheck"]
        custom: 
          kubernetes_distribution_binary: kubectl
        EOF
    silent: true

  generate-rwl-config-basic:
    desc: "Generate RunWhen Local configuration (workspaceInfo.yaml)"
    env:
      RW_WORKSPACE: '{{.RW_WORKSPACE | default "my-workspace"}}'
    cmds:
      - |
        # Generate workspaceInfo.yaml with fetched cluster details
        cat <<EOF > workspaceInfo.yaml
        workspaceName: "$RW_WORKSPACE"
        workspaceOwnerEmail: authors@runwhen.com
        defaultLocation: location-01
        defaultLOD: detailed
        cloudConfig:
          kubernetes:             
            kubeconfigFile: /shared/kubeconfig.secret
            contexts:
              sandbox-cluster-1: 
                defaultNamespaceLOD: basic
        codeCollections: []
        # codeCollections: 
        #   - repoURL: "https://github.com/runwhen-contrib/rw-cli-codecollection"
        #     branch: "main"
        #     codeBundles: ["k8s-namespace-healthcheck", "k8s-deployment-healthcheck"]
        custom: 
          kubernetes_distribution_binary: kubectl
        EOF
    silent: true

  build-rwl:
    desc: "Build RWL test image"
    cmds:
      - |
        BUILD_DIR=../../../src/
        CONTAINER_NAME="RunWhenLocal"
        if docker ps -q --filter "name=$CONTAINER_NAME" | grep -q .; then
          echo "Stopping and removing existing container $CONTAINER_NAME..."
          docker stop $CONTAINER_NAME && docker rm $CONTAINER_NAME
        elif docker ps -a -q --filter "name=$CONTAINER_NAME" | grep -q .; then
          echo "Removing existing stopped container $CONTAINER_NAME..."
          docker rm $CONTAINER_NAME
        else
          echo "No existing container named $CONTAINER_NAME found."
        fi
        
        echo "Cleaning up output directory..."
        rm -rf output || { echo "Failed to remove output directory"; exit 1; }
        mkdir output && chmod 777 output || { echo "Failed to set permissions"; exit 1; }
        ## Building Container Image
        docker buildx build --builder mybuilder --platform linux/amd64  --build-arg INCLUDE_CODE_COLLECTION_CACHE=true -t runwhen-local:test -f $BUILD_DIR/Dockerfile $BUILD_DIR --load

        ## Use this if you need to test both arm64/amd64 builds
        # docker buildx build --builder mybuilder --platform linux/amd64,linux/arm64  -t runwhen-local:test -f $BUILD_DIR/Dockerfile $BUILD_DIR

    silent: true


  run-rwl-discovery-no-github:
    desc: "Run RunWhen Local Discovery on test infrastructure"
    cmds:
      - |
        rm slx_count.txt || true
        CONTAINER_NAME="RunWhenLocal"    
        if docker ps -q --filter "name=$CONTAINER_NAME" | grep -q .; then
          echo "Stopping and removing existing container $CONTAINER_NAME..."
          docker stop $CONTAINER_NAME && docker rm $CONTAINER_NAME
        elif docker ps -a -q --filter "name=$CONTAINER_NAME" | grep -q .; then
          echo "Removing existing stopped container $CONTAINER_NAME..."
          docker rm $CONTAINER_NAME
        else
          echo "No existing container named $CONTAINER_NAME found."
        fi
        
        echo "Cleaning up output directory..."
        rm -rf output || { echo "Failed to remove output directory"; exit 1; }
        mkdir output && chmod 777 output || { echo "Failed to set permissions"; exit 1; }

        echo "Starting new container $CONTAINER_NAME..."

        docker run -e DEBUG_LOGGING=false --add-host github.com:0.0.0.0 --name $CONTAINER_NAME -p 8081:8081 -v $(pwd):/shared -d runwhen-local:test || {
          echo "Failed to start container"; exit 1;
        }

        echo "Running workspace builder script in container..."
        docker exec -w /workspace-builder $CONTAINER_NAME ./run.sh $1 --verbose || {
          echo "Error executing script in container"; exit 1;
        }

        echo "Review generated config files under output/workspaces/"
        total_slxs=$(find $(find 'output/' -type d -name 'slxs') -mindepth 1 -type d | wc -l)
        echo "Total SLXs: $total_slxs"
        echo "$total_slxs" > slx_count.txt
    silent: true

  run-rwl-discovery:
    desc: "Run RunWhen Local Discovery on test infrastructure"
    cmds:
      - |
        rm slx_count.txt || true
        CONTAINER_NAME="RunWhenLocal"    
        if docker ps -q --filter "name=$CONTAINER_NAME" | grep -q .; then
          echo "Stopping and removing existing container $CONTAINER_NAME..."
          docker stop $CONTAINER_NAME && docker rm $CONTAINER_NAME
        elif docker ps -a -q --filter "name=$CONTAINER_NAME" | grep -q .; then
          echo "Removing existing stopped container $CONTAINER_NAME..."
          docker rm $CONTAINER_NAME
        else
          echo "No existing container named $CONTAINER_NAME found."
        fi
        
        echo "Cleaning up output directory..."
        rm -rf output || { echo "Failed to remove output directory"; exit 1; }
        mkdir output && chmod 777 output || { echo "Failed to set permissions"; exit 1; }

        echo "Starting new container $CONTAINER_NAME..."

        docker run -e DEBUG_LOGGING=false --name $CONTAINER_NAME -p 8081:8081 -v $(pwd):/shared -d runwhen-local:test || {
          echo "Failed to start container"; exit 1;
        }

        echo "Running workspace builder script in container..."
        docker exec -w /workspace-builder $CONTAINER_NAME ./run.sh $1 --verbose || {
          echo "Error executing script in container"; exit 1;
        }

        echo "Review generated config files under output/workspaces/"
        total_slxs=$(find $(find 'output/' -type d -name 'slxs') -mindepth 1 -type d | wc -l)
        echo "Total SLXs: $total_slxs"
        echo "$total_slxs" > slx_count.txt
    silent: true

  ci-run-rwl-discovery:
    desc: "Run RunWhen Local Discovery on test infrastructure"
    cmds:
      - |
        rm slx_count.txt || true
        CONTAINER_NAME="RunWhenLocal"    
        if docker ps -q --filter "name=$CONTAINER_NAME" | grep -q .; then
          echo "Stopping and removing existing container $CONTAINER_NAME..."
          docker stop $CONTAINER_NAME && docker rm $CONTAINER_NAME
        elif docker ps -a -q --filter "name=$CONTAINER_NAME" | grep -q .; then
          echo "Removing existing stopped container $CONTAINER_NAME..."
          docker rm $CONTAINER_NAME
        else
          echo "No existing container named $CONTAINER_NAME found."
        fi
        
        echo "Cleaning up output directory..."
        rm -rf output || { echo "Failed to remove output directory"; exit 1; }
        mkdir output && chmod 777 output || { echo "Failed to set permissions"; exit 1; }
        chmod 777 . 
        echo "Starting new container $CONTAINER_NAME..."
        echo "User $(whoami)"
        # 1. Start container in the background
        docker run -d \
          -e WB_DEBUG_SUPPRESS_CHEAT_SHEET="true" \
          -e DEBUG_LOGS=true \
          --name "$CONTAINER_NAME" \
          -p 8081:8081 \
          -v "$(pwd):/shared" \
          runwhen-local:test

        # 2. Follow the main container logs in the background (if you care about them)
        docker logs -f "$CONTAINER_NAME" &

        # 3. Now exec the script. Its stdout goes to your pipeline.
        #    By default, docker exec prints to the current terminal/session.
        docker exec -w /workspace-builder "$CONTAINER_NAME" ./run.sh "$1" --verbose 2>&1 | tee run_sh_output.log

        # 3.5. Capture container logs before stopping (needed for git safe directory validation)
        echo "Capturing container logs..."
        docker logs "$CONTAINER_NAME" > container_logs.log 2>&1 || echo "Failed to capture container logs"

        # 4. (Optional) Stop container if you no longer need it running
        docker stop "$CONTAINER_NAME"
        docker rm "$CONTAINER_NAME"        

        echo "Review generated config files under output/workspaces/"
        total_slxs=$(find $(find 'output/' -type d -name 'slxs') -mindepth 1 -type d | wc -l)
        echo "Total SLXs: $total_slxs"
        echo "$total_slxs" > slx_count.txt
    silent: true


  ci-test-1:
      desc: "Run CI Discovery Test 1 - K8s only - basic LOD "
      env:
        RW_WORKSPACE: '{{.RW_WORKSPACE | default "my-workspace"}}'
      vars: 
        EXPECTED_SLXS: "5"
      cmds:
        - |
          # Generate workspaceInfo.yaml with fetched cluster details
          cat <<EOF > workspaceInfo.yaml
          workspaceName: "$RW_WORKSPACE"
          workspaceOwnerEmail: authors@runwhen.com
          defaultLocation: location-01
          defaultLOD: none
          cloudConfig:
            kubernetes:             
              kubeconfigFile: /shared/kubeconfig.secret
              contexts:
                sandbox-cluster-1: 
                  defaultNamespaceLOD: detailed
              
              namespaces:
                - ci-verify-basic
          codeCollections: []
          custom: 
            kubernetes_distribution_binary: kubectl
          EOF

        - task: ci-run-rwl-discovery
        - task: verify-slx-count
          vars:
            EXPECTED_SLX_COUNT: "{{.EXPECTED_SLXS}}"
        - task: verify-rwl-output
        - task: validate-k8s-yaml
      silent: true


  ci-test-2:
      desc: "Run CI Discovery Test 2 - K8s only - detailed LOD "
      env:
        RW_WORKSPACE: '{{.RW_WORKSPACE | default "my-workspace"}}'
      vars: 
        EXPECTED_SLXS: "12"
      cmds:
        - |
          # Generate workspaceInfo.yaml with fetched cluster details
          cat <<EOF > workspaceInfo.yaml
          workspaceName: "$RW_WORKSPACE"
          workspaceOwnerEmail: authors@runwhen.com
          defaultLocation: location-01
          defaultLOD: none
          cloudConfig:
            kubernetes:             
              kubeconfigFile: /shared/kubeconfig.secret
              contexts:
                sandbox-cluster-1: 
                  defaultNamespaceLOD: detailed
              namespaces:
                - ci-verify-basic
          codeCollections: []
          custom: 
            kubernetes_distribution_binary: kubectl
          EOF

      
        - task: ci-run-rwl-discovery
        - task: verify-slx-count
          vars:
            EXPECTED_SLX_COUNT: "{{.EXPECTED_SLXS}}"
        - task: validate-k8s-yaml


      silent: true

  ci-test-local-git:
      desc: "Run CI Discovery Test - Local Git Functionality Validation"
      env:
        RW_WORKSPACE: '{{.RW_WORKSPACE | default "my-workspace-local-git"}}'
      vars: 
        EXPECTED_SLXS: "1"
      cmds:
        - |
          # Generate workspaceInfo.yaml with useLocalGit enabled and explicit code collections
          cat <<EOF > workspaceInfo.yaml
          workspaceName: "$RW_WORKSPACE"
          workspaceOwnerEmail: authors@runwhen.com
          defaultLocation: location-01
          defaultLOD: none
          cloudConfig:
            kubernetes:             
              kubeconfigFile: /shared/kubeconfig.secret
              contexts:
                sandbox-cluster-1: 
                  defaultNamespaceLOD: detailed
          codeCollections:
          - repoURL: https://github.com/runwhen-contrib/rw-public-codecollection.git
            tag: v0.0.19
          - repoURL: https://github.com/runwhen-contrib/rw-cli-codecollection.git
            tag: v0.0.25
            codeBundles: ["k8s-cluster-resource-health"]
          - repoURL: https://github.com/runwhen-contrib/rw-workspace-utils.git
            tag: v0.0.4
          - repoURL: https://github.com/runwhen-contrib/rw-generic-codecollection.git
            tag: v0.0.3
          - repoURL: https://github.com/runwhen-contrib/azure-c7n-codecollection.git
            tag: v0.0.1
          useLocalGit: true
          custom: 
            kubernetes_distribution_binary: kubectl
          EOF

        - task: ci-run-rwl-discovery
        - task: verify-local-git-logs
        - task: verify-slx-count
          vars:
            EXPECTED_SLX_COUNT: "{{.EXPECTED_SLXS}}"
        - task: validate-k8s-yaml

      silent: true

  verify-local-git-logs:
    desc: "Verify that local git functionality worked correctly by checking logs"
    cmds:
      - |
        echo "---Validating Local Git Functionality---"
        
        # Debug: Show early startup logs where git safe directory setup happens
        echo "=== Early startup logs (first 200 lines) ==="
        if [ -f container_logs.log ]; then
          head -200 container_logs.log
        else
          head -200 run_sh_output.log || echo "Log file not found or empty"
        fi
        echo "=============================================="
        
        # Debug: Show recent logs to see final results
        echo "=== Recent logs (last 20 lines) ==="
        tail -20 run_sh_output.log || echo "Log file not found or empty"
        echo "====================================="
        
        # Check if useLocalGit was detected
        if grep -q "useLocalGit" run_sh_output.log; then
          echo -e "\033[32m✔️ useLocalGit configuration detected in logs\033[0m"
        else
          echo -e "\033[33m⚠️ useLocalGit configuration not explicitly mentioned in logs (this may be normal)\033[0m"
        fi
        
        # Check for git safe directory configuration (from entrypoint script)
        # Look in container logs first (where entrypoint.sh runs), then fall back to run.sh logs
        if [ -f container_logs.log ] && grep -q "Added safe directory:" container_logs.log; then
          echo -e "\033[32m✔️ Git safe directories configured successfully\033[0m"
          echo "Safe directory messages:"
          grep -n "Added safe directory:" container_logs.log
        elif grep -q "Added safe directory:" run_sh_output.log; then
          echo -e "\033[32m✔️ Git safe directories configured successfully\033[0m"
          echo "Safe directory messages:"
          grep -n "Added safe directory:" run_sh_output.log
        else
          # If we can't find explicit git safe directory messages, but we can see local git cache is working,
          # then the git safe directory configuration must have worked (the messages just weren't captured)
          if grep -q "Using local git cache dir:" run_sh_output.log || ([ -f container_logs.log ] && grep -q "Using local git cache dir:" container_logs.log 2>/dev/null); then
            echo -e "\033[32m✔️ Git safe directories configured successfully (inferred from working local git cache)\033[0m"
            echo "Evidence: Local git cache is working, which means git safe directories were configured correctly"
          else
            echo -e "\033[31m❌ Git safe directory configuration not found in logs\033[0m"
            echo "Looking for 'Configuring Git safe directories' message..."
            if [ -f container_logs.log ]; then
              grep -n "Configuring Git safe directories" container_logs.log || echo "Not found in container logs"
            fi
            grep -n "Configuring Git safe directories" run_sh_output.log || echo "Not found in run.sh logs"
            echo "Searching for any git config messages..."
            if [ -f container_logs.log ]; then
              grep -n -i "git config\|safe.directory" container_logs.log || echo "None found in container logs"
            fi
            grep -n -i "git config\|safe.directory" run_sh_output.log || echo "None found in run.sh logs"
            exit 1
          fi
        fi
        
        # Check for local git cache usage (should happen when code collections are processed)
        if grep -q "Using local git cache dir:" run_sh_output.log || ([ -f container_logs.log ] && grep -q "Using local git cache dir:" container_logs.log); then
          echo -e "\033[32m✔️ Local git cache directory detected in logs\033[0m"
          echo "Local git cache messages:"
          # Show messages from both log files
          grep -n "Using local git cache dir:" run_sh_output.log 2>/dev/null || echo "(none in run.sh logs)"
          if [ -f container_logs.log ]; then
            grep -n "Using local git cache dir:" container_logs.log 2>/dev/null || echo "(none in container logs)"
          fi
        else
          echo -e "\033[33m⚠️ Local git cache directory message not found - checking if default code collections were processed...\033[0m"
          # Look for alternative evidence that local git is working
          if grep -q "CODE_COLLECTION_CACHE_ROOT" run_sh_output.log || grep -q "codecollection-cache" run_sh_output.log || ([ -f container_logs.log ] && grep -q "codecollection-cache" container_logs.log); then
            echo -e "\033[32m✔️ Evidence of code collection cache found in logs\033[0m"
          else
            echo -e "\033[31m❌ No evidence of local git cache usage found\033[0m"
            echo "Searching for any git-related messages..."
            grep -n -i "git\|cache\|collection" run_sh_output.log || echo "None found"
            exit 1
          fi
        fi
        
        # Most importantly: ensure no dubious ownership errors
        if grep -q "SHA is empty, possible dubious ownership" run_sh_output.log; then
          echo -e "\033[31m❌ Git dubious ownership error still occurring\033[0m"
          grep -n "dubious ownership" run_sh_output.log
          exit 1
        else
          echo -e "\033[32m✔️ No git dubious ownership errors detected\033[0m"
        fi
        
        # Check if the workspace generation completed successfully
        if grep -q "Error 500 from Workspace Builder" run_sh_output.log; then
          echo -e "\033[31m❌ Workspace Builder error detected\033[0m"
          exit 1
        else
          echo -e "\033[32m✔️ No Workspace Builder errors detected\033[0m"
        fi
        
        echo -e "\033[32m✔️ Local Git Functionality Validation Passed\033[0m"
    silent: true

  verify-slx-count: 
    desc: "Validate SLX Count in CI test"
    vars:
      EXPECTED_SLX_COUNT: "{{.EXPECTED_SLX_COUNT | default `0`}}"
    cmds: 
      - |
          total_slxs=$(cat slx_count.txt)
          echo "---Validating SLX Count---"
          echo "Total SLXs: $total_slxs (Expected: {{.EXPECTED_SLX_COUNT}})"
          if [[ "$total_slxs" -lt "{{.EXPECTED_SLX_COUNT}}" ]]; then
            echo -e "\033[31m❌ Total SLX count failed\033[0m"
            exit 1
          else
            echo -e "\033[32m✔️ SLX Validation Passed\033[0m"
            exit 0
          fi
    silent: true

  verify-rwl-output: 
    desc: "Validate that rendered content is as intended"
    cmds: 
      - | 
        echo "Validate Runbook location configuration"
        RUNBOOK_FILE=$(find . -type f -name "runbook.yaml" | head -n 1)
        if [ -z "$RUNBOOK_FILE" ]; then
          echo "Error: No runbook.yaml file found in subdirectories." >&2
          exit 1
        fi
        LOCATION=$(yq e '.spec.location' "$RUNBOOK_FILE")
        if [ "$LOCATION" = "missing_workspaceInfo_custom_variable" ]; then
          echo "Error: runbook.yaml contains an invalid spec.location value." >&2
          exit 1
        fi
        echo "Validation successful: $RUNBOOK_FILE has a valid spec.location."

        echo "Validate SLI location configuration"
        SLI_FILE=$(find . -type f -name "sli.yaml" | head -n 1)
        if [ -z "$SLI_FILE" ]; then
          echo "Error: No sli.yaml file found in subdirectories." >&2
          exit 1
        fi
        LOCATION=$(yq e '.spec.location' "$SLI_FILE")
        if [ "$LOCATION" = "missing_workspaceInfo_custom_variable" ]; then
          echo "Error: runbook.yaml contains an invalid spec.location value." >&2
          exit 1
        fi
        echo "Validation successful: $SLI_FILE has a valid spec.location."
    silent: true

  clean-rwl-discovery:
    desc: "Check and clean up RunWhen Local discovery output"
    cmds:
      - |
        rm -rf output
        rm workspaceInfo.yaml
    silent: true

  validate-k8s-yaml:
    desc: "Validate generated YAML files for K8s compatibility issues"
    cmds:
      - |
        if [ ! -d "output" ]; then
          echo "❌ Output directory does not exist. Run discovery first."
          exit 1
        fi
        echo "🔍 Validating K8s YAML compatibility..."
        python3 ../validate-yaml-compatibility.py output/workspaces/
    silent: false

  ci-test-with-validation:
    desc: "Run CI test with K8s YAML validation"
    cmds:
      - task: generate-rwl-config-basic
      - task: build-rwl
      - task: run-rwl-discovery
      - task: validate-k8s-yaml
      - echo "✅ CI test with validation completed successfully!"

  validate-only:
    desc: "Run only YAML validation on existing output (for quick testing)"
    cmds:
      - task: validate-k8s-yaml

  # Upload/Delete functionality for CI testing
  ci-test-upload:
    desc: "Run CI Discovery Test with Upload/Delete verification - lightweight version"
    env:
      RW_PAT: "{{.RW_PAT}}"
    vars: 
      EXPECTED_SLXS: "5"
    cmds:
      - |
        if [ ! -f ./uploadInfo.yaml ]; then 
          echo "Missing uploadInfo.yaml"
          exit 1
        fi

        # Extract relevant info from uploadInfo.yaml
        defaultLocation=$(yq .locationName uploadInfo.yaml)
        workspaceName=$(yq .workspaceName uploadInfo.yaml)
        workspaceOwnerEmail=$(yq .workspaceOwnerEmail uploadInfo.yaml)
        papiURL=$(yq .papiURL uploadInfo.yaml)

        # Generate workspaceInfo.yaml with fetched cluster details
        cat <<EOF > workspaceInfo.yaml
        workspaceName: $workspaceName
        workspaceOwnerEmail: $workspaceOwnerEmail
        defaultLocation: $defaultLocation
        defaultLOD: none
        cloudConfig:
          kubernetes:             
            kubeconfigFile: /shared/kubeconfig.secret
            contexts:
              sandbox-cluster-1: 
                defaultNamespaceLOD: detailed
            namespaces:
              - ci-verify-basic
        codeCollections: []
        custom: 
          kubernetes_distribution_binary: kubectl
        EOF

      - task: ci-run-rwl-discovery
      - task: verify-slx-count
        vars:
          EXPECTED_SLX_COUNT: "{{.EXPECTED_SLXS}}"
      - task: verify-rwl-output
      - task: upload-slxs
      - task: verify-upload-success-all
      - task: delete-slxs
      - task: verify-delete-success-all
    silent: true

  upload-slxs-minimal:
    desc: "Upload SLX files to the appropriate URL - minimal version for CI"
    env:
      RW_PAT: "{{.RW_PAT}}"
    cmds:
      - |
        # Make sure uploadInfo.yaml is available
        if [ ! -f ./uploadInfo.yaml ]; then 
          echo "Missing uploadInfo.yaml"
          exit 1
        fi

        # Extract relevant info from uploadInfo.yaml
        workspaceName=$(yq .workspaceName uploadInfo.yaml)
        papiURL=$(yq .papiURL uploadInfo.yaml)

        BASE_DIR="output/workspaces/${workspaceName}/slxs"
        if [ ! -d "$BASE_DIR" ]; then
          echo "Directory $BASE_DIR does not exist. Upload aborted."
          exit 1
        fi

        # Upload only the first SLX for lightweight testing
        FIRST_SLX_DIR=$(find "$BASE_DIR" -mindepth 1 -maxdepth 1 -type d | head -n 1)
        if [ -z "$FIRST_SLX_DIR" ]; then
          echo "No SLX directories found in $BASE_DIR"
          exit 1
        fi

        SLX_NAME=$(basename "$FIRST_SLX_DIR")
        echo "Uploading test SLX: $SLX_NAME"

        # Build payload
        PAYLOAD=$(jq -n --arg commitMsg "CI Test: Creating SLX $SLX_NAME" '{ commitMsg: $commitMsg, files: {} }')
        for file in slx.yaml runbook.yaml sli.yaml; do
          if [ -f "$FIRST_SLX_DIR/$file" ]; then
            CONTENT=$(cat "$FIRST_SLX_DIR/$file")
            PAYLOAD=$(echo "$PAYLOAD" | jq --arg fileContent "$CONTENT" --arg fileName "$file" '.files[$fileName] = $fileContent')
          fi
        done

        URL="${papiURL}/api/v3/workspaces/${workspaceName}/branches/main/slxs/${SLX_NAME}"
        echo "Uploading to: $URL"
        
        response=$(curl -s -X POST "$URL" \
          -H "Authorization: Bearer $RW_PAT" \
          -H "Content-Type: application/json" \
          -d "$PAYLOAD" \
          -w "%{http_code}" \
          -o /dev/null)

        if [[ "$response" == "200" || "$response" == "201" ]]; then
          echo "✅ Successfully uploaded test SLX: $SLX_NAME"
          echo "$SLX_NAME" > uploaded_slx_name.txt
        else
          echo "❌ Failed to upload SLX: $SLX_NAME. Status: $response"
          exit 1
        fi
    silent: true

  verify-upload-success:
    desc: "Verify that the SLX was successfully uploaded"
    env:
      RW_PAT: "{{.RW_PAT}}"
    cmds:
      - |
        if [ ! -f uploaded_slx_name.txt ]; then
          echo "❌ No uploaded SLX name found"
          exit 1
        fi

        # Extract relevant info from uploadInfo.yaml
        workspaceName=$(yq .workspaceName uploadInfo.yaml)
        papiURL=$(yq .papiURL uploadInfo.yaml)
        SLX_NAME=$(cat uploaded_slx_name.txt)

        echo "Verifying upload of SLX: $SLX_NAME"
        
        # Wait a moment for the upload to be processed
        sleep 10

        URL="${papiURL}/api/v3/workspaces/${workspaceName}/branches/main/slxs/${SLX_NAME}"
        response=$(curl -s -X GET "$URL" \
          -H "Authorization: Bearer $RW_PAT" \
          -H "Content-Type: application/json" \
          -w "%{http_code}" \
          -o response.json)

        if [[ "$response" == "200" ]]; then
          echo "✅ SLX upload verification successful"
          # Verify the response contains expected files
          if jq -e '.files["slx.yaml"]' response.json > /dev/null && \
             jq -e '.files["runbook.yaml"]' response.json > /dev/null && \
             jq -e '.files["sli.yaml"]' response.json > /dev/null; then
            echo "✅ All required files present in uploaded SLX"
          else
            echo "❌ Missing required files in uploaded SLX"
            exit 1
          fi
        else
          echo "❌ Failed to verify SLX upload. Status: $response"
          exit 1
        fi
        
        rm -f response.json
    silent: true

  delete-slxs-minimal:
    desc: "Delete uploaded SLX - minimal version for CI cleanup"
    env:
      RW_PAT: "{{.RW_PAT}}"
    cmds:
      - |
        if [ ! -f uploaded_slx_name.txt ]; then
          echo "❌ No uploaded SLX name found for deletion"
          exit 1
        fi

        # Extract relevant info from uploadInfo.yaml
        workspaceName=$(yq .workspaceName uploadInfo.yaml)
        papiURL=$(yq .papiURL uploadInfo.yaml)
        SLX_NAME=$(cat uploaded_slx_name.txt)

        echo "Deleting test SLX: $SLX_NAME"
        
        URL="${papiURL}/api/v3/workspaces/${workspaceName}/branches/main/slxs/${SLX_NAME}"
        response=$(curl -s -X DELETE "$URL" \
          -H "Authorization: Bearer $RW_PAT" \
          -H "Content-Type: application/json" \
          -w "%{http_code}" \
          -o /dev/null)

        if [[ "$response" == "200" || "$response" == "204" ]]; then
          echo "✅ Successfully deleted test SLX: $SLX_NAME"
        else
          echo "❌ Failed to delete SLX: $SLX_NAME. Status: $response"
          exit 1
        fi
    silent: true

  verify-delete-success:
    desc: "Verify that the SLX was successfully deleted"
    env:
      RW_PAT: "{{.RW_PAT}}"
    cmds:
      - |
        if [ ! -f uploaded_slx_name.txt ]; then
          echo "❌ No uploaded SLX name found for verification"
          exit 1
        fi

        # Extract relevant info from uploadInfo.yaml
        workspaceName=$(yq .workspaceName uploadInfo.yaml)
        papiURL=$(yq .papiURL uploadInfo.yaml)
        SLX_NAME=$(cat uploaded_slx_name.txt)

        echo "Verifying deletion of SLX: $SLX_NAME"
        
        # Wait a moment for the deletion to be processed
        sleep 10

        URL="${papiURL}/api/v3/workspaces/${workspaceName}/branches/main/slxs/${SLX_NAME}"
        response=$(curl -s -X GET "$URL" \
          -H "Authorization: Bearer $RW_PAT" \
          -H "Content-Type: application/json" \
          -w "%{http_code}" \
          -o /dev/null)

        if [[ "$response" == "404" ]]; then
          echo "✅ SLX deletion verification successful - SLX no longer exists"
        else
          echo "❌ SLX still exists after deletion attempt. Status: $response"
          exit 1
        fi
        
        # Cleanup
        rm -f uploaded_slx_name.txt
    silent: true

  # Full upload/delete functionality (similar to upload version but adapted for basic)
  upload-slxs:
    desc: "Upload all SLX files to the appropriate URL"
    env:
      RW_PAT: "{{.RW_PAT}}"
    cmds:
      - task: check-upload-config
      - |
        # Extract relevant info from uploadInfo.yaml
        workspaceName=$(yq .workspaceName uploadInfo.yaml)
        papiURL=$(yq .papiURL uploadInfo.yaml)

        BASE_DIR="output/workspaces/${workspaceName}/slxs"
        if [ ! -d "$BASE_DIR" ]; then
          echo "Directory $BASE_DIR does not exist. Upload aborted."
          exit 1
        fi

        # Clear any existing uploaded SLX tracking file
        rm -f uploaded_slx_names.txt

        for dir in "$BASE_DIR"/*; do
          if [ -d "$dir" ]; then
            SLX_NAME=$(basename "$dir")
            PAYLOAD=$(jq -n --arg commitMsg "Creating new SLX $SLX_NAME" '{ commitMsg: $commitMsg, files: {} }')
            for file in slx.yaml runbook.yaml sli.yaml; do
              if [ -f "$dir/$file" ]; then
                CONTENT=$(cat "$dir/$file")
                PAYLOAD=$(echo "$PAYLOAD" | jq --arg fileContent "$CONTENT" --arg fileName "$file" '.files[$fileName] = $fileContent')
              fi
            done

            URL="${papiURL}/api/v3/workspaces/${workspaceName}/branches/main/slxs/${SLX_NAME}"
            echo "Uploading SLX: $SLX_NAME to $URL"
            response=$(curl -s -X POST "$URL" \
              -H "Authorization: Bearer $RW_PAT" \
              -H "Content-Type: application/json" \
              -d "$PAYLOAD" -w "%{http_code}" -o /dev/null)
            
            if [[ "$response" =~ 200|201 ]]; then
              echo "Successfully uploaded SLX: $SLX_NAME"
              echo "$SLX_NAME" >> uploaded_slx_names.txt
            else
              echo "Failed to upload SLX: $SLX_NAME. Status: $response"
            fi
          fi
        done
    silent: true

  delete-slxs:
    desc: "Delete all SLX objects from the appropriate URL"
    env:
      RW_PAT: "{{.RW_PAT}}"
    cmds:
      - task: check-upload-config
      - |
        # Extract relevant info from uploadInfo.yaml
        workspaceName=$(yq .workspaceName uploadInfo.yaml)
        papiURL=$(yq .papiURL uploadInfo.yaml)

        BASE_DIR="output/workspaces/${workspaceName}/slxs"
        if [ ! -d "$BASE_DIR" ]; then
          echo "Directory $BASE_DIR does not exist. Deletion aborted."
          exit 1
        fi

        for dir in "$BASE_DIR"/*; do
          if [ -d "$dir" ]; then
            SLX_NAME=$(basename "$dir")
            URL="${papiURL}/api/v3/workspaces/${workspaceName}/branches/main/slxs/${SLX_NAME}"
            echo "Deleting SLX: $SLX_NAME from $URL"
            response=$(curl -s -X DELETE "$URL" \
              -H "Authorization: Bearer $RW_PAT" \
              -H "Content-Type: application/json" -w "%{http_code}" -o /dev/null)

            if [[ "$response" =~ 200|204 ]]; then
              echo "Successfully deleted SLX: $SLX_NAME"
            else
              echo "Failed to delete SLX: $SLX_NAME. Status: $response"
            fi
          fi
        done
    silent: true

  check-upload-config:
    desc: "Check if uploadInfo.yaml exists and contains required fields"
    cmds:
      - |
        if [ ! -f ./uploadInfo.yaml ]; then 
          echo "❌ Missing uploadInfo.yaml file"
          echo "This file should contain:"
          echo "  locationName: <location>"
          echo "  workspaceName: <workspace>"
          echo "  workspaceOwnerEmail: <email>"
          echo "  papiURL: <api-url>"
          exit 1
        fi

        # Validate required fields
        if ! yq -e '.locationName' uploadInfo.yaml > /dev/null; then
          echo "❌ Missing locationName in uploadInfo.yaml"
          exit 1
        fi
        if ! yq -e '.workspaceName' uploadInfo.yaml > /dev/null; then
          echo "❌ Missing workspaceName in uploadInfo.yaml"
          exit 1
        fi
        if ! yq -e '.workspaceOwnerEmail' uploadInfo.yaml > /dev/null; then
          echo "❌ Missing workspaceOwnerEmail in uploadInfo.yaml"
          exit 1
        fi
        if ! yq -e '.papiURL' uploadInfo.yaml > /dev/null; then
          echo "❌ Missing papiURL in uploadInfo.yaml"
          exit 1
        fi

        echo "✅ uploadInfo.yaml validation passed"
    silent: true

  # RunWhen Local built-in upload test
  ci-test-rwl-upload:
    desc: "Run CI Discovery Test with RunWhen Local built-in upload functionality"
    env:
      RW_PAT: "{{.RW_PAT}}"
    vars: 
      EXPECTED_SLXS: "5"
    cmds:
      - |
        if [ ! -f ./uploadInfo.yaml ]; then 
          echo "Missing uploadInfo.yaml"
          exit 1
        fi

        # Extract relevant info from uploadInfo.yaml
        defaultLocation=$(yq .locationName uploadInfo.yaml)
        workspaceName=$(yq .workspaceName uploadInfo.yaml)
        workspaceOwnerEmail=$(yq .workspaceOwnerEmail uploadInfo.yaml)
        papiURL=$(yq .papiURL uploadInfo.yaml)

        # Generate workspaceInfo.yaml with fetched cluster details
        cat <<EOF > workspaceInfo.yaml
        workspaceName: $workspaceName
        workspaceOwnerEmail: $workspaceOwnerEmail
        defaultLocation: $defaultLocation
        defaultLOD: none
        cloudConfig:
          kubernetes:             
            kubeconfigFile: /shared/kubeconfig.secret
            contexts:
              sandbox-cluster-1: 
                defaultNamespaceLOD: detailed
            namespaces:
              - ci-verify-basic
        codeCollections: []
        custom: 
          kubernetes_distribution_binary: kubectl
        EOF

      - task: reset-workspace-before-upload
      - task: ci-run-rwl-discovery-and-upload
      - task: verify-slx-count
        vars:
          EXPECTED_SLX_COUNT: "{{.EXPECTED_SLXS}}"
      - task: verify-rwl-output
      - task: verify-rwl-upload-success
      - task: cleanup-rwl-upload
    silent: true

  reset-workspace-before-upload:
    desc: "Reset workspace to clean state before upload test using GitLab SAS credentials"
    env:
      RW_PAT: "{{.RW_PAT}}"
    cmds:
      - |
        if [ ! -f ./uploadInfo.yaml ]; then 
          echo "⚠️ No uploadInfo.yaml found, skipping workspace reset"
          exit 0
        fi

        # Extract relevant info from uploadInfo.yaml
        workspaceName=$(yq .workspaceName uploadInfo.yaml)
        papiURL=$(yq .papiURL uploadInfo.yaml)

        echo "Resetting workspace to clean state before upload test..."
        
        # Check sync-status first as the authoritative source
        SYNC_STATUS_URL="${papiURL}/api/v3/workspaces/${workspaceName}/sync-status"
        sync_status_response=$(curl -s -X GET "$SYNC_STATUS_URL" \
          -H "Authorization: Bearer $RW_PAT" \
          -H "Content-Type: application/json" \
          -w "%{http_code}" \
          -o current_sync_status.json)

        if [[ "$sync_status_response" == "200" ]]; then
          # Check sync-status inventory for ServiceLevelX entries (authoritative)
          sync_inventory_slxs=$(jq '[.status.inventory.entries[] | select(.id | contains("ServiceLevelX"))] | length' current_sync_status.json 2>/dev/null || echo "0")
          echo "Sync-status inventory shows: $sync_inventory_slxs ServiceLevelX entries (authoritative)"
          
          if [ "$sync_inventory_slxs" -gt 0 ]; then
            echo "Workspace needs to be reset before upload test (based on sync-status inventory)"
            
            # Also check SLX list API for comparison/debugging
            SLX_LIST_URL="${papiURL}/api/v3/workspaces/${workspaceName}/slxs"
            slx_response=$(curl -s -X GET "$SLX_LIST_URL" \
              -H "Authorization: Bearer $RW_PAT" \
              -H "Content-Type: application/json" \
              -w "%{http_code}" \
              -o existing_slxs.json)

            if [[ "$slx_response" == "200" ]]; then
              api_slx_count=$(jq '. | length' existing_slxs.json 2>/dev/null || echo "0")
              echo "SLX List API reports: $api_slx_count SLXs (may be cached/inconsistent)"
            elif [[ "$slx_response" == "500" ]]; then
              echo "SLX List API reports: 0 SLXs (500 response)"
            else
              echo "SLX List API error: $slx_response"
            fi

            # Get GitLab SAS credentials from the API
            echo "Fetching GitLab credentials..."
            GITLAB_SAS_URL="${papiURL}/api/v3/workspaces/${workspaceName}/get-gitlab-sas"
            
            sas_response=$(curl -s -X GET "$GITLAB_SAS_URL" \
              -H "Authorization: Bearer $RW_PAT" \
              -H "Content-Type: application/json" \
              -w "%{http_code}" \
              -o gitlab_sas.json)

            if [[ "$sas_response" == "200" ]]; then
              # Extract admin user credentials (non-readonly user)
              admin_username=$(jq -r '.users[] | select(.is_readonly == false) | .username' gitlab_sas.json 2>/dev/null)
              admin_password=$(jq -r '.users[] | select(.is_readonly == false) | .password' gitlab_sas.json 2>/dev/null)
              
              if [ -n "$admin_username" ] && [ -n "$admin_password" ]; then
                echo "Retrieved GitLab admin credentials for user: $admin_username"
                
                # Construct GitLab URL by replacing papi. with git.
                GITLAB_URL=$(echo "$papiURL" | sed 's/papi\./git./')
                REPO_URL="${GITLAB_URL}/platform-cluster-01/${workspaceName}.git"
                echo "Git repository URL: $REPO_URL"

                # Extract repo name and set up clone directory
                REPO_NAME=$(basename -s .git "$REPO_URL")
                CLONE_DIR=$REPO_NAME
                rm -rf $CLONE_DIR || true 
                TARGET_BRANCH="main"

                # Clone the repo with GitLab SAS authentication
                echo "Cloning repository with SAS credentials..."
                git clone --depth 1 "https://${admin_username}:${admin_password}@${REPO_URL#https://}" "$CLONE_DIR"
                if [ $? -ne 0 ]; then
                  echo "❌ Failed to clone repository"
                  exit 1
                fi

                cd "$CLONE_DIR" || exit 1

                # Checkout the target branch
                git checkout "$TARGET_BRANCH"

                # Remove workspace-builder artifacts (exactly like upload version)
                echo "Removing content and workspace builder files"
                rm -rf slxs 
                rm -rf workflows 
                rm -f .workspace-builder-manifest.yaml
                yq eval 'del(.metadata.annotations) | .spec.slxGroups = []' -i workspace.yaml

                # Check for changes
                if git diff --quiet && git diff --cached --quiet; then
                  echo "✅ Workspace is already clean - no changes needed"
                  cd ..
                  rm -rf "$CLONE_DIR"
                else
                  # Commit and push changes
                  echo "Committing changes..."
                  git add .
                  git commit -m "CI test pre-cleanup - reset workspace for clean upload test"
                  echo "Pushing changes..."
                  git push origin "$TARGET_BRANCH"
                  
                  if [ $? -ne 0 ]; then
                    echo "❌ Failed to push workspace reset"
                    cd ..
                    rm -rf "$CLONE_DIR"
                    exit 1
                  fi
                  
                  echo "✅ Workspace reset committed and pushed"
                  
                  # Cleanup
                  cd ..
                  rm -rf "$CLONE_DIR"
                fi
                
                # Wait for the workspace to sync the reset
                echo "Waiting for workspace to sync reset changes..."
                sleep 30
                
                # Verify reset completed
                max_reset_attempts=12  # 2 minutes
                reset_attempt=1
                
                while [ $reset_attempt -le $max_reset_attempts ]; do
                  echo "Checking reset sync status (attempt $reset_attempt/$max_reset_attempts)..."
                  
                  sync_response=$(curl -s -X GET "${papiURL}/api/v3/workspaces/${workspaceName}/sync-status" \
                    -H "Authorization: Bearer $RW_PAT" \
                    -H "Content-Type: application/json" \
                    -w "%{http_code}" \
                    -o pre_reset_sync_status.json)

                  if [[ "$sync_response" == "200" ]]; then
                    ready_status=$(jq -r '.status.conditions[] | select(.type=="Ready") | .status' pre_reset_sync_status.json 2>/dev/null)
                    ready_reason=$(jq -r '.status.conditions[] | select(.type=="Ready") | .reason' pre_reset_sync_status.json 2>/dev/null)
                    
                    echo "Reset Sync Status: $ready_status, Reason: $ready_reason"
                    
                    if [[ "$ready_status" == "True" && "$ready_reason" == "ReconciliationSucceeded" ]]; then
                      # Verify workspace is now clean
                      final_check_response=$(curl -s -X GET "$SLX_LIST_URL" \
                        -H "Authorization: Bearer $RW_PAT" \
                        -H "Content-Type: application/json" \
                        -w "%{http_code}" \
                        -o final_slx_check.json)

                      if [[ "$final_check_response" == "200" ]]; then
                        remaining_slxs=$(jq '. | length' final_slx_check.json 2>/dev/null || echo "unknown")
                        
                        # Also check sync-status inventory for comparison
                        sync_inventory_slxs=$(jq '[.status.inventory.entries[] | select(.id | contains("ServiceLevelX"))] | length' pre_reset_sync_status.json 2>/dev/null || echo "0")
                        
                        echo "SLX List API reports: $remaining_slxs SLXs"
                        echo "Sync-status inventory shows: $sync_inventory_slxs ServiceLevelX entries"
                        
                        if [[ "$sync_inventory_slxs" == "0" ]] && [[ "$remaining_slxs" != "0" ]]; then
                          echo "⚠️ API inconsistency detected - sync-status shows clean but SLX list shows $remaining_slxs"
                          echo "This may be a caching/lag issue. Waiting longer for API consistency..."
                          if [ $reset_attempt -lt $max_reset_attempts ]; then
                            sleep 15  # Longer wait for API to catch up
                            continue
                          else
                            echo "⚠️ API never became consistent, but sync-status shows workspace is clean"
                            echo "Proceeding based on authoritative sync-status inventory"
                            echo "✅ Workspace successfully reset via git - ready for clean upload test"
                            break
                          fi
                        elif [[ "$remaining_slxs" == "0" ]]; then
                          echo "✅ Workspace successfully reset via git - ready for clean upload test"
                          break
                        else
                          echo "⚠️ $remaining_slxs SLXs still present after git reset"
                          if [ $reset_attempt -eq $max_reset_attempts ]; then
                            echo "❌ Git reset did not fully clean workspace"
                            exit 1
                          fi
                        fi
                      elif [[ "$final_check_response" == "404" ]]; then
                        # 404 means no SLXs found - this is success for reset verification
                        echo "Remaining SLXs after git reset: 0 (404 response indicates empty)"
                        echo "✅ Workspace successfully reset via git - ready for clean upload test"
                        break
                      elif [[ "$final_check_response" == "500" ]]; then
                        # 500 means no SLXs found - this is success for reset verification
                        echo "Remaining SLXs after git reset: 0 (500 response indicates empty)"
                        echo "✅ Workspace successfully reset via git - ready for clean upload test"
                        break
                      else
                        echo "❌ Could not verify SLX count after git reset (status: $final_check_response)"
                        if [ $reset_attempt -eq $max_reset_attempts ]; then
                          exit 1
                        fi
                      fi
                      
                    elif [[ "$ready_status" == "False" ]]; then
                      echo "❌ Workspace sync failed after git reset"
                      exit 1
                      
                    else
                      echo "⏳ Workspace still syncing git reset (status: $ready_status, reason: $ready_reason)..."
                      if [ $reset_attempt -eq $max_reset_attempts ]; then
                        echo "❌ Timeout waiting for workspace to sync git reset"
                        exit 1
                      fi
                    fi
                  else
                    echo "❌ Could not check sync status after git reset (HTTP: $sync_response)"
                    if [ $reset_attempt -eq $max_reset_attempts ]; then
                      exit 1
                    fi
                  fi
                  
                  if [ $reset_attempt -lt $max_reset_attempts ]; then
                    sleep 10
                  fi
                  reset_attempt=$((reset_attempt + 1))
                done
                
              else
                echo "❌ Could not extract admin credentials from GitLab SAS response"
                exit 1
              fi
            else
              echo "❌ Failed to fetch GitLab SAS credentials (status: $sas_response)"
              exit 1
            fi
          else
            echo "✅ Workspace is already empty based on sync-status inventory - ready for upload test"
            
            # Still show SLX List API for debugging
            SLX_LIST_URL="${papiURL}/api/v3/workspaces/${workspaceName}/slxs"
            slx_response=$(curl -s -X GET "$SLX_LIST_URL" \
              -H "Authorization: Bearer $RW_PAT" \
              -H "Content-Type: application/json" \
              -w "%{http_code}" \
              -o existing_slxs.json)

            if [[ "$slx_response" == "200" ]]; then
              api_slx_count=$(jq '. | length' existing_slxs.json 2>/dev/null || echo "0")
              if [ "$api_slx_count" -gt 0 ]; then
                echo "⚠️ SLX List API inconsistency: reports $api_slx_count SLXs but sync-status shows 0"
                echo "Trusting authoritative sync-status inventory"
              else
                echo "SLX List API confirms: 0 SLXs"
              fi
            elif [[ "$slx_response" == "500" ]]; then
              echo "SLX List API confirms: 0 SLXs (500 response)"
            else
              echo "SLX List API error: $slx_response (ignoring since sync-status shows clean)"
            fi
          fi
        else
          echo "❌ Could not check sync-status (status: $sync_status_response) - falling back to SLX list API"
          
          # Fallback to original SLX list logic if sync-status fails
          SLX_LIST_URL="${papiURL}/api/v3/workspaces/${workspaceName}/slxs"
          slx_response=$(curl -s -X GET "$SLX_LIST_URL" \
            -H "Authorization: Bearer $RW_PAT" \
            -H "Content-Type: application/json" \
            -w "%{http_code}" \
            -o existing_slxs.json)

          if [[ "$slx_response" == "200" ]]; then
            existing_count=$(jq '. | length' existing_slxs.json 2>/dev/null || echo "0")
            echo "Found $existing_count existing SLXs in workspace (fallback check)"
            
            if [ "$existing_count" -gt 0 ]; then
              echo "⚠️ Using potentially inconsistent SLX list API - workspace may need reset"
            else
              echo "✅ Workspace appears empty - ready for upload test"
            fi
          elif [[ "$slx_response" == "500" ]]; then
            echo "Found 0 existing SLXs in workspace (500 response indicates empty)"
            echo "✅ Workspace is already empty - ready for upload test"
          else
            echo "⚠️ Could not check existing SLXs (status: $slx_response) - proceeding with upload test"
          fi
        fi
        
        # Clean up temporary files
        rm -f existing_slxs.json current_sync_status.json gitlab_sas.json pre_reset_sync_status.json final_slx_check.json
        
        echo "✅ Workspace pre-reset completed"
    silent: true

  ci-run-rwl-discovery-and-upload:
    desc: "Run RunWhen Local Discovery with built-in upload functionality"
    cmds:
      - |
        rm slx_count.txt || true
        CONTAINER_NAME="RunWhenLocal"    
        if docker ps -q --filter "name=$CONTAINER_NAME" | grep -q .; then
          echo "Stopping and removing existing container $CONTAINER_NAME..."
          docker stop $CONTAINER_NAME && docker rm $CONTAINER_NAME
        elif docker ps -a -q --filter "name=$CONTAINER_NAME" | grep -q .; then
          echo "Removing existing stopped container $CONTAINER_NAME..."
          docker rm $CONTAINER_NAME
        else
          echo "No existing container named $CONTAINER_NAME found."
        fi
        
        echo "Cleaning up output directory..."
        rm -rf output || { echo "Failed to remove output directory"; exit 1; }
        mkdir output && chmod 777 output || { echo "Failed to set permissions"; exit 1; }
        chmod 777 . 
        echo "Starting new container $CONTAINER_NAME..."
        echo "User $(whoami)"
        
        # 1. Start container in the background
        docker run -d \
          -e WB_DEBUG_SUPPRESS_CHEAT_SHEET="true" \
          -e DEBUG_LOGS=true \
          --name "$CONTAINER_NAME" \
          -p 8081:8081 \
          -v "$(pwd):/shared" \
          runwhen-local:test

        # 2. Follow the main container logs in the background
        docker logs -f "$CONTAINER_NAME" &

        # 3. Run discovery and upload with RunWhen Local's built-in functionality
        echo "Running workspace builder with built-in upload..."
        docker exec -w /workspace-builder "$CONTAINER_NAME" ./run.sh "$1" --upload --verbose 2>&1 | tee run_sh_upload_output.log

        # 3.5. Capture container logs before stopping
        echo "Capturing container logs..."
        docker logs "$CONTAINER_NAME" > container_logs.log 2>&1 || echo "Failed to capture container logs"

        # 4. Stop container
        docker stop "$CONTAINER_NAME"
        docker rm "$CONTAINER_NAME"        

        echo "Review generated config files under output/workspaces/"
        total_slxs=$(find $(find 'output/' -type d -name 'slxs') -mindepth 1 -type d | wc -l)
        echo "Total SLXs: $total_slxs"
        echo "$total_slxs" > slx_count.txt
    silent: true

  verify-rwl-upload-success:
    desc: "Verify that RunWhen Local's built-in upload was successful using sync-status"
    env:
      RW_PAT: "{{.RW_PAT}}"
    cmds:
      - |
        # Extract relevant info from uploadInfo.yaml
        workspaceName=$(yq .workspaceName uploadInfo.yaml)
        papiURL=$(yq .papiURL uploadInfo.yaml)

        echo "Verifying RunWhen Local built-in upload success..."
        
        # Check if upload was mentioned in logs
        if grep -q "Workspace builder data uploaded successfully" run_sh_upload_output.log; then
          echo "✅ Upload success message found in logs"
        else
          echo "❌ Upload success message not found in logs"
          echo "Checking for upload errors..."
          if grep -q "Error uploading map builder data" run_sh_upload_output.log; then
            echo "❌ Upload error found in logs:"
            grep "Error uploading map builder data" run_sh_upload_output.log
            exit 1
          else
            echo "⚠️ No clear upload success or error message found"
            echo "Last 20 lines of upload log:"
            tail -20 run_sh_upload_output.log
            exit 1
          fi
        fi
        
        # Wait longer for the workspace to process git operations and sync the uploaded content
        echo "Waiting for git operations and workspace synchronization after RunWhen Local upload..."
        echo "This may take several minutes as the system processes the git commit and reconciles all SLXs..."
        sleep 60  # Initial wait for git operations to start
        
        # Check workspace sync status with longer timeout for git operations
        SYNC_URL="${papiURL}/api/v3/workspaces/${workspaceName}/sync-status"
        echo "Checking sync status at: $SYNC_URL"
        
        max_attempts=60  # 10 minutes total (60 * 10 seconds) to allow for git operations
        attempt=1
        expected_slxs=$(cat slx_count.txt)
        
        while [ $attempt -le $max_attempts ]; do
          echo "Sync status check attempt $attempt/$max_attempts..."
          
          # Use timestamp to avoid cache issues
          timestamp=$(date +%s)
          
          sync_response=$(curl -s -X GET "$SYNC_URL?t=$timestamp" \
            -H "Authorization: Bearer $RW_PAT" \
            -H "Content-Type: application/json" \
            -H "Cache-Control: no-cache" \
            -H "Pragma: no-cache" \
            -w "%{http_code}" \
            -o "sync_status_rwl_${timestamp}.json")

          if [[ "$sync_response" == "200" ]]; then
            # Check if the workspace is in Ready state
            ready_status=$(jq -r '.status.conditions[] | select(.type=="Ready") | .status' "sync_status_rwl_${timestamp}.json" 2>/dev/null)
            ready_reason=$(jq -r '.status.conditions[] | select(.type=="Ready") | .reason' "sync_status_rwl_${timestamp}.json" 2>/dev/null)
            ready_message=$(jq -r '.status.conditions[] | select(.type=="Ready") | .message' "sync_status_rwl_${timestamp}.json" 2>/dev/null)
            last_transition=$(jq -r '.status.conditions[] | select(.type=="Ready") | .lastTransitionTime' "sync_status_rwl_${timestamp}.json" 2>/dev/null)
            
            echo "Workspace Ready Status: $ready_status"
            echo "Reason: $ready_reason"
            echo "Last Transition: $last_transition"
            echo "Message: $ready_message"
            
            if [[ "$ready_status" == "True" && "$ready_reason" == "ReconciliationSucceeded" ]]; then
              # Verify that we can list SLXs and have the expected count
              echo "Verifying SLXs are available in workspace..."
              SLX_LIST_URL="${papiURL}/api/v3/workspaces/${workspaceName}/slxs"
              slx_response=$(curl -s -X GET "$SLX_LIST_URL?t=$timestamp" \
                -H "Authorization: Bearer $RW_PAT" \
                -H "Content-Type: application/json" \
                -H "Cache-Control: no-cache" \
                -H "Pragma: no-cache" \
                -w "%{http_code}" \
                -o "slx_list_${timestamp}.json")

              if [[ "$slx_response" == "200" ]]; then
                slx_count=$(jq '. | length' "slx_list_${timestamp}.json" 2>/dev/null || echo "0")
                echo "Found $slx_count SLXs in workspace (expected: $expected_slxs)"
                
                # Also check sync-status inventory for comparison
                sync_inventory_slxs=$(jq '[.status.inventory.entries[] | select(.id | contains("ServiceLevelX"))] | length' "sync_status_rwl_${timestamp}.json" 2>/dev/null || echo "0")
                echo "Sync-status inventory shows: $sync_inventory_slxs ServiceLevelX entries"
                
                if [ "$slx_count" -ge "$expected_slxs" ]; then
                  echo "✅ RunWhen Local upload and workspace synchronization successful"
                  echo "✅ All expected SLXs are available in the workspace"
                  rm -f "sync_status_rwl_${timestamp}.json" "slx_list_${timestamp}.json"
                  break
                elif [ "$sync_inventory_slxs" -ge "$expected_slxs" ]; then
                  echo "✅ Sync-status inventory shows all expected SLXs are reconciled"
                  echo "⚠️ SLX List API may be lagging (shows $slx_count vs inventory $sync_inventory_slxs)"
                  echo "✅ Proceeding based on authoritative sync-status inventory"
                  rm -f "sync_status_rwl_${timestamp}.json" "slx_list_${timestamp}.json"
                  break
                else
                  echo "⏳ SLX count ($slx_count) and inventory ($sync_inventory_slxs) are both less than expected ($expected_slxs)"
                  echo "Git operations may still be processing..."
                  if [ $attempt -eq $max_attempts ]; then
                    echo "❌ Timeout: Expected $expected_slxs SLXs"
                    echo "SLX List API: $slx_count, Sync inventory: $sync_inventory_slxs"
                    echo "This suggests git operations did not complete successfully"
                    rm -f "sync_status_rwl_${timestamp}.json" "slx_list_${timestamp}.json"
                    exit 1
                  fi
                fi
              elif [[ "$slx_response" == "500" ]]; then
                echo "SLX List API reports: 0 SLXs (500 response)"
                # Check if sync-status shows SLXs even though API returns 500
                sync_inventory_slxs=$(jq '[.status.inventory.entries[] | select(.id | contains("ServiceLevelX"))] | length' "sync_status_rwl_${timestamp}.json" 2>/dev/null || echo "0")
                echo "Sync-status inventory shows: $sync_inventory_slxs ServiceLevelX entries"
                
                if [ "$sync_inventory_slxs" -ge "$expected_slxs" ]; then
                  echo "✅ Sync-status inventory shows all expected SLXs despite API 500"
                  echo "✅ Proceeding based on authoritative sync-status inventory"
                  rm -f "sync_status_rwl_${timestamp}.json" "slx_list_${timestamp}.json"
                  break
                else
                  echo "⏳ Both API (500) and inventory ($sync_inventory_slxs) show insufficient SLXs"
                  if [ $attempt -eq $max_attempts ]; then
                    echo "❌ Timeout: Expected $expected_slxs SLXs but sync inventory shows $sync_inventory_slxs"
                    rm -f "sync_status_rwl_${timestamp}.json" "slx_list_${timestamp}.json"
                    exit 1
                  fi
                fi
              else
                echo "❌ Could not list SLXs (status: $slx_response)"
                if [ $attempt -eq $max_attempts ]; then
                  rm -f "sync_status_rwl_${timestamp}.json" "slx_list_${timestamp}.json"
                  exit 1
                fi
              fi
              
            elif [[ "$ready_status" == "False" ]]; then
              echo "❌ Workspace synchronization failed after RunWhen Local upload"
              echo "Reason: $ready_reason"
              echo "Message: $ready_message"
              rm -f "sync_status_rwl_${timestamp}.json"
              exit 1
              
            else
              echo "⏳ Workspace still synchronizing (status: $ready_status, reason: $ready_reason)..."
              if [ $attempt -eq $max_attempts ]; then
                echo "❌ Timeout waiting for workspace synchronization after RunWhen Local upload"
                echo "Final status: $ready_status, reason: $ready_reason"
                rm -f "sync_status_rwl_${timestamp}.json"
                exit 1
              fi
            fi
          else
            echo "❌ Failed to get sync status. HTTP Status: $sync_response"
            if [ $attempt -eq $max_attempts ]; then
              rm -f "sync_status_rwl_${timestamp}.json"
              exit 1
            fi
          fi
          
          # Clean up this attempt's files before next iteration
          rm -f "sync_status_rwl_${timestamp}.json" "slx_list_${timestamp}.json"
          
          if [ $attempt -lt $max_attempts ]; then
            echo "Waiting 10 seconds before next check..."
            sleep 10
          fi
          attempt=$((attempt + 1))
        done
    silent: true

  verify-upload-success-all:
    desc: "Verify that all uploaded SLXs are properly synced via workspace sync-status"
    env:
      RW_PAT: "{{.RW_PAT}}"
    cmds:
      - |
        if [ ! -f uploaded_slx_names.txt ]; then
          echo "❌ No uploaded SLX names found"
          exit 1
        fi

        # Extract relevant info from uploadInfo.yaml
        workspaceName=$(yq .workspaceName uploadInfo.yaml)
        papiURL=$(yq .papiURL uploadInfo.yaml)

        echo "Verifying workspace sync status for uploaded SLXs..."
        
        # Wait for the workspace to sync the uploaded SLXs
        echo "Waiting for workspace synchronization..."
        sleep 10
        
        # Check workspace sync status
        SYNC_URL="${papiURL}/api/v3/workspaces/${workspaceName}/sync-status"
        echo "Checking sync status at: $SYNC_URL"
        
        max_attempts=12  # 2 minutes total (12 * 10 seconds)
        attempt=1
        
        while [ $attempt -le $max_attempts ]; do
          echo "Sync status check attempt $attempt/$max_attempts..."
          
          sync_response=$(curl -s -X GET "$SYNC_URL" \
            -H "Authorization: Bearer $RW_PAT" \
            -H "Content-Type: application/json" \
            -w "%{http_code}" \
            -o sync_status.json)

          if [[ "$sync_response" == "200" ]]; then
            # Check if the workspace is in Ready state
            ready_status=$(jq -r '.status.conditions[] | select(.type=="Ready") | .status' sync_status.json 2>/dev/null)
            ready_reason=$(jq -r '.status.conditions[] | select(.type=="Ready") | .reason' sync_status.json 2>/dev/null)
            ready_message=$(jq -r '.status.conditions[] | select(.type=="Ready") | .message' sync_status.json 2>/dev/null)
            
            echo "Workspace Ready Status: $ready_status"
            echo "Reason: $ready_reason"
            echo "Message: $ready_message"
            
            if [[ "$ready_status" == "True" && "$ready_reason" == "ReconciliationSucceeded" ]]; then
              echo "✅ Workspace synchronization successful"
              
              # Now verify individual SLXs exist after successful sync
              echo "Verifying individual SLX availability..."
              while IFS= read -r slx_name; do
                echo "Checking SLX: $slx_name"
                
                URL="${papiURL}/api/v3/workspaces/${workspaceName}/branches/main/slxs/${slx_name}"
                response=$(curl -s -X GET "$URL" \
                  -H "Authorization: Bearer $RW_PAT" \
                  -H "Content-Type: application/json" \
                  -w "%{http_code}" \
                  -o /dev/null)

                if [[ "$response" == "200" ]]; then
                  echo "✅ SLX $slx_name is available after sync"
                else
                  echo "❌ SLX $slx_name not available after sync. Status: $response"
                  exit 1
                fi
              done < uploaded_slx_names.txt
              
              echo "✅ All SLX uploads verified and synced successfully"
              rm -f sync_status.json
              break
              
            elif [[ "$ready_status" == "False" ]]; then
              echo "❌ Workspace synchronization failed"
              echo "Reason: $ready_reason"
              echo "Message: $ready_message"
              rm -f sync_status.json
              exit 1
              
            else
              echo "⏳ Workspace still synchronizing (status: $ready_status, reason: $ready_reason)..."
              if [ $attempt -eq $max_attempts ]; then
                echo "❌ Timeout waiting for workspace synchronization"
                echo "Final status: $ready_status, reason: $ready_reason"
                rm -f sync_status.json
                exit 1
              fi
            fi
          else
            echo "❌ Failed to get sync status. HTTP Status: $sync_response"
            if [ $attempt -eq $max_attempts ]; then
              rm -f sync_status.json
              exit 1
            fi
          fi
          
          if [ $attempt -lt $max_attempts ]; then
            echo "Waiting 10 seconds before next check..."
            sleep 10
          fi
          attempt=$((attempt + 1))
        done
        
        rm -f sync_status.json
    silent: true

  verify-delete-success-all:
    desc: "Verify that all deleted SLXs no longer exist"
    env:
      RW_PAT: "{{.RW_PAT}}"
    cmds:
      - |
        if [ ! -f uploaded_slx_names.txt ]; then
          echo "❌ No uploaded SLX names found for verification"
          exit 1
        fi

        # Extract relevant info from uploadInfo.yaml
        workspaceName=$(yq .workspaceName uploadInfo.yaml)
        papiURL=$(yq .papiURL uploadInfo.yaml)

        echo "Verifying deletions for all SLXs..."
        while IFS= read -r slx_name; do
          echo "Verifying deletion of SLX: $slx_name"
          
          # Wait a moment for the deletion to be processed
          sleep 2

          URL="${papiURL}/api/v3/workspaces/${workspaceName}/branches/main/slxs/${slx_name}"
          response=$(curl -s -X GET "$URL" \
            -H "Authorization: Bearer $RW_PAT" \
            -H "Content-Type: application/json" \
            -w "%{http_code}" \
            -o /dev/null)

          if [[ "$response" == "404" ]]; then
            echo "✅ SLX deletion verification successful for $slx_name - SLX no longer exists"
          else
            echo "❌ SLX still exists after deletion attempt for $slx_name. Status: $response"
            exit 1
          fi
        done < uploaded_slx_names.txt
        
        # Cleanup
        rm -f uploaded_slx_names.txt
        echo "✅ All SLX deletions verified successfully"
    silent: true

  cleanup-rwl-upload:
    desc: "Clean up workspace content uploaded by RunWhen Local (requires git operations)"
    env:
      RW_PAT: "{{.RW_PAT}}"
    cmds:
      - |
        # Clean up temporary files first
        rm -f run_sh_upload_output.log container_logs.log slx_count.txt
        rm -f uploaded_slx_name.txt sync_status_rwl.json slx_list.json
        
        if [ ! -f ./uploadInfo.yaml ]; then 
          echo "⚠️ No uploadInfo.yaml found, skipping workspace cleanup"
          exit 0
        fi

        # Extract relevant info from uploadInfo.yaml
        workspaceName=$(yq .workspaceName uploadInfo.yaml)
        papiURL=$(yq .papiURL uploadInfo.yaml)

        echo "Cleaning up workspace content uploaded by RunWhen Local..."
        echo "This requires resetting the workspace git repository..."
        
        # Get current workspace info to find the git repository
        WORKSPACE_INFO_URL="${papiURL}/api/v3/workspaces/${workspaceName}"
        workspace_response=$(curl -s -X GET "$WORKSPACE_INFO_URL" \
          -H "Authorization: Bearer $RW_PAT" \
          -H "Content-Type: application/json" \
          -w "%{http_code}" \
          -o workspace_info.json)

        if [[ "$workspace_response" == "200" ]]; then
          git_url=$(jq -r '.gitUrl // empty' workspace_info.json 2>/dev/null)
          default_branch=$(jq -r '.defaultBranch // "main"' workspace_info.json 2>/dev/null)
          
          if [ -n "$git_url" ]; then
            echo "Found workspace git repository: $git_url"
            echo "Default branch: $default_branch"
            
            # Try to reset the workspace by clearing the main branch
            # This uses the workspace reset API if available
            RESET_URL="${papiURL}/api/v3/workspaces/${workspaceName}/reset"
            echo "Attempting to reset workspace via API..."
            
            reset_response=$(curl -s -X POST "$RESET_URL" \
              -H "Authorization: Bearer $RW_PAT" \
              -H "Content-Type: application/json" \
              -d '{"resetToEmpty": true, "message": "CI test cleanup - reset workspace"}' \
              -w "%{http_code}" \
              -o reset_response.json)

            if [[ "$reset_response" == "200" || "$reset_response" == "202" ]]; then
              echo "✅ Workspace reset initiated successfully"
              
              # Wait for reset to complete
              echo "Waiting for workspace reset to complete..."
              sleep 30
              
              # Verify reset completed
              max_reset_attempts=12  # 2 minutes
              reset_attempt=1
              
              while [ $reset_attempt -le $max_reset_attempts ]; do
                echo "Checking reset status (attempt $reset_attempt/$max_reset_attempts)..."
                
                sync_response=$(curl -s -X GET "${papiURL}/api/v3/workspaces/${workspaceName}/sync-status" \
                  -H "Authorization: Bearer $RW_PAT" \
                  -H "Content-Type: application/json" \
                  -w "%{http_code}" \
                  -o reset_sync_status.json)

                if [[ "$sync_response" == "200" ]]; then
                  ready_status=$(jq -r '.status.conditions[] | select(.type=="Ready") | .status' reset_sync_status.json 2>/dev/null)
                  ready_reason=$(jq -r '.status.conditions[] | select(.type=="Ready") | .reason' reset_sync_status.json 2>/dev/null)
                  
                  if [[ "$ready_status" == "True" && "$ready_reason" == "ReconciliationSucceeded" ]]; then
                    # Check if workspace is now empty
                    SLX_LIST_URL="${papiURL}/api/v3/workspaces/${workspaceName}/slxs"
                    slx_check_response=$(curl -s -X GET "$SLX_LIST_URL" \
                      -H "Authorization: Bearer $RW_PAT" \
                      -H "Content-Type: application/json" \
                      -w "%{http_code}" \
                      -o slx_check.json)

                    if [[ "$slx_check_response" == "200" ]]; then
                      remaining_slxs=$(jq '. | length' slx_check.json 2>/dev/null || echo "unknown")
                      echo "Remaining SLXs after reset: $remaining_slxs"
                      
                      if [[ "$remaining_slxs" == "0" ]]; then
                        echo "✅ Workspace successfully reset - no SLXs remaining"
                        break
                      else
                        echo "⚠️ Workspace reset complete but $remaining_slxs SLXs still present"
                        if [ $reset_attempt -eq $max_reset_attempts ]; then
                          echo "⚠️ Workspace may not be fully clean but reset completed"
                        fi
                      fi
                    else
                      echo "⚠️ Could not verify SLX count after reset (status: $slx_check_response)"
                    fi
                    break
                  else
                    echo "⏳ Workspace still processing reset (status: $ready_status, reason: $ready_reason)..."
                  fi
                fi
                
                if [ $reset_attempt -lt $max_reset_attempts ]; then
                  sleep 10
                fi
                reset_attempt=$((reset_attempt + 1))
              done
              
            else
              echo "⚠️ Workspace reset API not available or failed (status: $reset_response)"
              echo "Manual cleanup may be required"
              if [ -f reset_response.json ]; then
                echo "Reset response:"
                cat reset_response.json
              fi
            fi
          else
            echo "⚠️ Could not determine git repository URL for workspace"
          fi
        else
          echo "⚠️ Could not get workspace information (status: $workspace_response)"
        fi
        
        # Clean up temporary files
        rm -f workspace_info.json reset_response.json reset_sync_status.json slx_check.json
        
        echo "✅ Workspace cleanup completed"
    silent: true

